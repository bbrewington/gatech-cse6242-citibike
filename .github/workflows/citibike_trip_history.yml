name: 'Citibike Trip History: Extract AWS Zip & Load CSV to GCS'

on:
  schedule:
    - cron: '* 23 * * *'
  push:
    branches:
      - 'main'

jobs:
  citibike_trip_history_EL:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - name: checkout
      uses: actions/checkout@v3

    - id: 'auth'
      uses: 'google-github-actions/auth@v0'
      with:
        credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

    - name: 'Set up Cloud SDK'
      uses: 'google-github-actions/setup-gcloud@v0'

    - name: Install python libraries
      run: |
        pip install --upgrade pip
        pip install --upgrade protobuf
        pip install --upgrade boto3 google-cloud-storage

    - name: Extract from AWS, Load to GCS
      run: python src/copy_aws_to_gcs.py --aws_access_key_id ${{ secrets.AWS_ACCESS_KEY }} --aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Load from GCS to GBQ
      run: python src/gcs_to_gbq.py
    
  citibike_trip_history_T:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
    - name: checkout
      uses: actions/checkout@v3

    - id: 'auth'
      uses: 'google-github-actions/auth@v0'
      with:
        credentials_json: '${{ secrets.GCP_CREDENTIALS }}'

    - name: 'Set up Cloud SDK'
      uses: 'google-github-actions/setup-gcloud@v0'

    - name: Install python libraries
      run: pip install --upgrade dbt-bigquery

    - name: dbt run (dev environment)
      run: dbt run --project-dir data/citibike_dbt --target dev
    
    - name: dbt test (dev environment)
      run: dbt test --project-dir data/citibike_dbt --target dev
    
    - name: dbt run (prod environment) if tests pass
      run: dbt run --project-dir data/citibike_dbt --target prod
